{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b65570a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b69d6",
   "metadata": {},
   "source": [
    "Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ad6d8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('src/boston.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fddc8bd",
   "metadata": {},
   "source": [
    "Преобразуем данные в массив numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9c412218",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = df.drop(df.columns[-1], axis=1).to_numpy()\n",
    "y_np = df['MEDV'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0641e375",
   "metadata": {},
   "source": [
    "Преобразуем данные в обычные массивы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "9496b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_np.tolist()\n",
    "y = y_np.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2657f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_np(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "    # Проверка входных данных\n",
    "    if X.shape[0] != y.shape[0]:\n",
    "        raise ValueError(\"Количество строк в X и y должно совпадать.\")\n",
    "    if not 0 < test_size < 1:\n",
    "        raise ValueError(\"test_size должен быть между 0 и 1.\")\n",
    "\n",
    "    # Получаем количество образцов\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    # Вычисляем количество тестовых образцов\n",
    "    n_test_samples = int(n_samples * test_size)\n",
    "    \n",
    "    # Создаем случайную перестановку индексов\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    # Разделяем индексы\n",
    "    test_indices = indices[:n_test_samples]\n",
    "    train_indices = indices[n_test_samples:]\n",
    "    \n",
    "    # Разделяем данные\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3063fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X: list, y: list, test_size: float = 0.2, random_state: int = None) -> tuple:\n",
    "    \"\"\"\n",
    "    Разделяет данные на обучающую и тестовую выборки.\n",
    "    \n",
    "    :param X: Список признаков или входных данных\n",
    "    :param y: Список целевых значений или меток\n",
    "    :param test_size: Доля данных для тестовой выборки (от 0 до 1), по умолчанию 0.2\n",
    "    :param random_state: Управляет воспроизводимостью результатов, по умолчанию None\n",
    "    :return: Кортеж из четырех списков (X_train, X_test, y_train, y_test)\n",
    "    :raises ValueError: Если количество элементов в X и y не совпадает\n",
    "                       или если test_size не находится в диапазоне (0, 1)\n",
    "    \"\"\"\n",
    "    if not random_state is None:\n",
    "        random.seed(random_state)\n",
    "\n",
    "    # Проверка входных данных\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError('Количество элементов X и y должно совпадать')\n",
    "    if not 0 < test_size < 1:\n",
    "        raise ValueError('test_size должен быть между 0 и 1')\n",
    "\n",
    "    n_samples = len(X)\n",
    "    n_test_samples = int(n_samples * test_size)\n",
    "\n",
    "    # Случайная перестановка индексов\n",
    "    indexes = list(range(n_samples))\n",
    "    random.shuffle(indexes)\n",
    "\n",
    "    test_indexes = indexes[:n_test_samples]\n",
    "    train_indexes = indexes[n_test_samples:]\n",
    "\n",
    "    # Разделение данных\n",
    "    X_train = [X[i] for i in train_indexes]\n",
    "    X_test = [X[i] for i in test_indexes]\n",
    "    y_trian = [y[i] for i in train_indexes]\n",
    "    y_test = [y[i] for i in test_indexes]\n",
    "\n",
    "    return X_train, X_test, y_trian, y_test    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc75f87",
   "metadata": {},
   "source": [
    "Разделяем данные на тренировочные и тестовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "cf9744d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "057fbd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_np(X, y):\n",
    "\n",
    "    # 1. Подготовка данных: нормализация признаков\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_std = np.std(X, axis=0)\n",
    "    # Избегаем деления на ноль\n",
    "    X_std[X_std == 0] = 1\n",
    "    X_normalized = (X - X_mean) / X_std\n",
    "    \n",
    "    # Добавление столбца единиц для свободного члена (intercept)\n",
    "    m, n = X_normalized.shape\n",
    "    X_b = np.column_stack([np.ones(m), X_normalized])\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    weights = np.random.randn(n + 1) * 0.01\n",
    "\n",
    "    for i in range(50000):\n",
    "        y_pred = X_b @ weights\n",
    "        error = y_pred - y\n",
    "\n",
    "        gradient = (2 / m) * X_b.T @ error\n",
    "        weights = weights - learning_rate * gradient\n",
    "\n",
    "    return weights, X_mean, X_std\n",
    "\n",
    "def predict_np(X, weights, X_mean, X_std):\n",
    "    X_normalized = (X - X_mean) / X_std\n",
    "    m = X_normalized.shape[0]\n",
    "    X_b = np.column_stack([np.ones(m), X_normalized])\n",
    "    return X_b @ weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5b5d6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X: list, y: list, learning_rate: float = 0.001, tolerance: float = 1e-7) -> tuple:\n",
    "    \"\"\"\n",
    "    Линейная регрессия методом градиентного спуска.\n",
    "    \n",
    "    :param X: Список списков признаков (двумерный массив)\n",
    "    :param y: Список целевых значений (одномерный массив)\n",
    "    :param learning_rate: Скорость обучения для градиентного спуска, по умолчанию 0.001\n",
    "    :param tolerance: Порог сходимости для остановки обучения (минимальное изменение ошибки),\n",
    "        по умолчанию 1e-7\n",
    "    :return: Кортеж из трех элементов (weights, X_mean, X_std)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Нормализация признаков\n",
    "    # Среднее значение по каждому признаку\n",
    "    n_features = len(X[0])\n",
    "    X_mean = []\n",
    "    for i in range(n_features):\n",
    "        sum_val = sum(row[i] for row in X)\n",
    "        X_mean.append(sum_val / len(X))\n",
    "\n",
    "    # Стандартное отклонение по каждому признаку\n",
    "    X_std = []\n",
    "    for i in range(n_features):\n",
    "        sum_squared_diff = sum((row[i] - X_mean[i]) ** 2 for row in X)\n",
    "        std_val = math.sqrt(sum_squared_diff / len(X))\n",
    "        # Избегаение деления на ноль\n",
    "        if std_val == 0:\n",
    "            std_val = 1\n",
    "        X_std.append(std_val)\n",
    "\n",
    "    # Нормализация признаков\n",
    "    X_normalized = []\n",
    "    for i in range(len(X)):\n",
    "        normalized_row = []\n",
    "        for j in range(n_features):\n",
    "            normalized_value = (X[i][j] - X_mean[j] / X_std[j])\n",
    "            normalized_row.append(normalized_value)\n",
    "        X_normalized.append(normalized_row)\n",
    "\n",
    "    # Добавление столбца единиц для свободного члена (intercept)\n",
    "    m = len(X_normalized)\n",
    "    n = len(X_normalized[0])\n",
    "    X_b = []\n",
    "    for i in range(m):\n",
    "        X_normalized[i].append(1.0)\n",
    "        X_b.append(X_normalized[i])\n",
    "    \n",
    "    # Инициализация весов\n",
    "    weights = []\n",
    "    for i in range(n + 1):\n",
    "        # Генерирация случайных весов (в диапазоне [-0.01, 0.01])\n",
    "        random_weight = (random.random() - 0.5) * 0.2\n",
    "        weights.append(random_weight)\n",
    "\n",
    "    # Градиентный спуск\n",
    "    prev_error = float('inf')\n",
    "    iteration = 0\n",
    "    max_iteration = 100000\n",
    "    while iteration < max_iteration:\n",
    "        # Вычисление предиктов\n",
    "        y_pred = []\n",
    "        for i in range(m):\n",
    "            pred = 0\n",
    "            for j in range(n + 1):\n",
    "                pred += X_b[i][j] * weights[j]\n",
    "            y_pred.append(pred)\n",
    "\n",
    "        # Вычисление ошибок\n",
    "        error = []\n",
    "        for i in range(m):\n",
    "            error.append(y_pred[i] - y[i])\n",
    "\n",
    "        # Вычисление среднеквадратичной ошибки\n",
    "        mse = sum(e ** 2 for e in error) / m\n",
    "\n",
    "        if abs(prev_error - mse) < tolerance:\n",
    "            break\n",
    "\n",
    "        prev_error = mse\n",
    "\n",
    "        # Вычисление градиента\n",
    "        gradient = []\n",
    "        for i in range(n + 1):\n",
    "            grad_sum = 0\n",
    "            for j in range(m):\n",
    "                grad_sum += X_b[j][i] * error[j]\n",
    "            gradient.append((2 / m) * grad_sum)\n",
    "\n",
    "        # Обновление весов\n",
    "        for i in range(n + 1):\n",
    "            weights[i] = weights[i] - learning_rate * gradient[i]\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    return weights, X_mean, X_std\n",
    "\n",
    "def predict(X: list, weights: list, X_mean: list, X_std: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Делает предсказания на основе обученной модели линейной регрессии.\n",
    "    \n",
    "    :param X: Список списков признаков для предсказания\n",
    "    :param weights: Веса модели, полученные из linear_regression\n",
    "    :param X_mean: Средние значения признаков, использованные при обучении\n",
    "    :param X_std: Стандартные отклонения признаков, использованные при обучении\n",
    "    :return: Список предсказанных значений\n",
    "    \"\"\"\n",
    "\n",
    "    # Нормализция признаков\n",
    "    X_normalized = []\n",
    "    n_features = len(X[0]) if X else 0\n",
    "    for i in range(len(X)):\n",
    "        normalized_row = []\n",
    "        for j in range(n_features):\n",
    "            normalized_value = (X[i][j] - X_mean[j]) / X_std[j]\n",
    "            normalized_row.append(normalized_value)\n",
    "        X_normalized.append(normalized_row)\n",
    "    \n",
    "    # Добавление столбца единиц для свободного члена\n",
    "    m = len(X_normalized)\n",
    "    X_b = []\n",
    "    for i in range(m):\n",
    "        row = [1.0]  # столбец единиц\n",
    "        row.extend(X_normalized[i])\n",
    "        X_b.append(row)\n",
    "    \n",
    "    # Вычисление предсказаний\n",
    "    predictions = []\n",
    "    for i in range(m):\n",
    "        pred = 0\n",
    "        for j in range(len(weights)):\n",
    "            pred += X_b[i][j] * weights[j]\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "3079a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_np(X_np, y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f1bce925",
   "metadata": {},
   "outputs": [],
   "source": [
    "ww, xm, xs =linear_regression_np(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ac0739a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.848447827479163 \t\t 11.9 \t\t 17.29558059208722\n",
      "20.05356278048241 \t\t 20.3 \t\t 12.14881480303195\n",
      "37.481017779479146 \t\t 44.0 \t\t 22.481784461712497\n",
      "18.46883282968789 \t\t 20.8 \t\t 22.202188867535586\n",
      "17.94147498071456 \t\t 19.3 \t\t 37.16328631468496\n",
      "33.44899829816234 \t\t 28.5 \t\t 24.915254636052772\n",
      "34.553649294116425 \t\t 35.4 \t\t 19.455161955636836\n",
      "32.28074905358561 \t\t 31.1 \t\t 37.511092390231866\n",
      "22.16341604791499 \t\t 17.8 \t\t 24.429823483247873\n",
      "12.840653950377689 \t\t 10.5 \t\t 20.17208927329338\n",
      "22.5826612503387 \t\t 25.0 \t\t 14.374785228367998\n",
      "15.133134512320009 \t\t 14.9 \t\t 19.361639540292664\n",
      "23.140554787099454 \t\t 20.4 \t\t 32.25102801323425\n",
      "24.393009694453514 \t\t 20.5 \t\t 32.708276658353974\n",
      "21.504963495779116 \t\t 21.0 \t\t 22.869524474348186\n",
      "28.133910167261035 \t\t 26.6 \t\t 20.232744140187492\n",
      "13.221440761872563 \t\t 7.5 \t\t 17.18668530858755\n",
      "18.749205326883953 \t\t 18.0 \t\t 26.402739552736584\n",
      "30.534198435359954 \t\t 29.1 \t\t 14.626176241815624\n",
      "36.27393614383037 \t\t 33.3 \t\t 14.207647351941354\n",
      "17.301194070519216 \t\t 19.1 \t\t 20.527509791162387\n",
      "22.603551225082917 \t\t 22.7 \t\t 26.878898428919722\n",
      "19.31749309454109 \t\t 18.9 \t\t 17.031418608646725\n",
      "26.448193588470698 \t\t 20.7 \t\t 19.63704691330145\n",
      "25.279178811255306 \t\t 21.6 \t\t 19.0486053324832\n",
      "25.368684879073708 \t\t 18.5 \t\t 25.40253505801478\n",
      "17.92469906454074 \t\t 20.0 \t\t 18.26126587169554\n",
      "25.956327885761507 \t\t 22.0 \t\t 34.446340892853115\n",
      "15.193625611748482 \t\t 17.2 \t\t 23.774566559646427\n",
      "30.724599147831704 \t\t 25.1 \t\t 38.37102452699322\n",
      "22.56740755795458 \t\t 19.3 \t\t 21.174181054134532\n",
      "11.684231543132071 \t\t 12.7 \t\t 24.667869132256644\n",
      "12.135065631164544 \t\t 15.6 \t\t 36.12770079210807\n",
      "21.066458332998575 \t\t 18.8 \t\t 20.906521527835256\n",
      "36.986357135445196 \t\t 42.3 \t\t 15.931185451337491\n",
      "23.523950545767086 \t\t 19.4 \t\t 36.106391643322254\n",
      "17.92933038968802 \t\t 17.4 \t\t 16.545011214380345\n",
      "28.706789615150495 \t\t 23.3 \t\t 27.4126673411188\n",
      "17.37949644192724 \t\t 23.2 \t\t 29.28719501365522\n",
      "25.041469001524 \t\t 23.1 \t\t 21.24965774422977\n",
      "34.739192974064316 \t\t 33.8 \t\t 17.854472136580792\n",
      "12.029473432505473 \t\t 5.6 \t\t 22.392510963566224\n",
      "29.507514317321863 \t\t 22.5 \t\t 6.55162319068328\n",
      "17.23005505092652 \t\t 17.1 \t\t 9.718441392743866\n",
      "27.479285126007163 \t\t 22.0 \t\t 20.75049025935624\n",
      "27.4038618739216 \t\t 25.2 \t\t 33.20905455941134\n",
      "23.128952906230694 \t\t 21.7 \t\t 23.80072902209164\n",
      "20.874615222936495 \t\t 16.2 \t\t 21.586795681399288\n",
      "36.88884178388445 \t\t 50.0 \t\t 12.979487807352566\n",
      "15.012817266184737 \t\t 13.4 \t\t 8.72822362342302\n",
      "29.274350917699895 \t\t 25.0 \t\t 3.2791811609612154\n",
      "14.514500105345771 \t\t 11.5 \t\t 23.972222848689483\n",
      "20.61899833556128 \t\t 20.4 \t\t 28.607036488728234\n",
      "18.1233098360214 \t\t 12.6 \t\t 30.643939064853825\n",
      "18.590703550780052 \t\t 20.0 \t\t 25.59413474573382\n",
      "19.500818548114697 \t\t 19.9 \t\t 22.148375624477346\n",
      "30.686694112890276 \t\t 23.5 \t\t 22.915026116165265\n",
      "19.403684190454513 \t\t 14.6 \t\t 22.976572190213197\n",
      "17.280447172048657 \t\t 18.6 \t\t 24.86937281538803\n",
      "26.57747063019504 \t\t 22.8 \t\t 19.774073196902535\n",
      "29.294479928673752 \t\t 24.3 \t\t 21.77537987148875\n",
      "22.09764596253113 \t\t 21.7 \t\t 13.621258906723867\n",
      "23.759077738950694 \t\t 23.0 \t\t 20.423200323014765\n",
      "21.49427378929748 \t\t 21.8 \t\t 33.42476722031544\n",
      "37.739800890325945 \t\t 41.7 \t\t 23.972283164977114\n",
      "15.89274573110046 \t\t 20.1 \t\t 16.32857560053605\n",
      "35.77643706545475 \t\t 36.5 \t\t 24.60979272545209\n",
      "27.698304183330123 \t\t 24.5 \t\t 17.872580396884885\n",
      "13.352123391138688 \t\t 8.3 \t\t 38.79756965988672\n",
      "20.430146826473074 \t\t 21.4 \t\t 18.512476092921656\n",
      "14.758094479228205 \t\t 15.4 \t\t 25.999809100736055\n",
      "13.680557266559948 \t\t 11.3 \t\t 35.456652419827925\n",
      "28.535347444816203 \t\t 28.0 \t\t 18.53994008160405\n",
      "25.621299514983832 \t\t 24.0 \t\t 34.83993381942424\n",
      "7.255437814872483 \t\t 10.4 \t\t 21.32536104399864\n",
      "14.84434422313971 \t\t 14.8 \t\t 27.356592297988144\n",
      "18.774729743476193 \t\t 19.5 \t\t 19.205480573953086\n",
      "20.74600231228907 \t\t 24.5 \t\t 6.1284219643046285\n",
      "20.67405919089697 \t\t 23.1 \t\t 25.567527693653073\n",
      "22.58894889561308 \t\t 17.0 \t\t 22.489447908157086\n",
      "29.16594836245469 \t\t 26.4 \t\t 25.27380081685665\n",
      "25.733722562651018 \t\t 24.1 \t\t 25.203866280479183\n",
      "24.594669333040443 \t\t 19.1 \t\t 18.476828330781984\n",
      "24.54948992309098 \t\t 27.5 \t\t 19.547372850961686\n",
      "26.201083544213322 \t\t 23.9 \t\t 28.942758712750972\n",
      "42.776448484488604 \t\t 50.0 \t\t 31.713835225278082\n",
      "23.660729569384657 \t\t 20.8 \t\t 24.29082811774899\n",
      "19.844869499740053 \t\t 18.6 \t\t 20.649658642696906\n",
      "17.8650742650657 \t\t 17.8 \t\t 19.204963044918024\n",
      "18.732607658482138 \t\t 17.5 \t\t 19.108541438764995\n",
      "35.67562924826224 \t\t 35.2 \t\t 15.463976546439905\n",
      "17.413509558884734 \t\t 19.5 \t\t 25.57824626548256\n",
      "17.6898380659971 \t\t 13.9 \t\t 24.48449226906589\n",
      "20.61769700910512 \t\t 22.9 \t\t 30.771594485123202\n",
      "22.250975641889056 \t\t 16.5 \t\t 28.457643368376914\n",
      "19.88706492060262 \t\t 19.4 \t\t 27.627426095035975\n",
      "20.71282049569049 \t\t 18.3 \t\t 26.91395839359891\n",
      "27.79797683825507 \t\t 23.9 \t\t 26.60334774762085\n",
      "35.568224907376695 \t\t 35.1 \t\t 31.226735925933074\n",
      "40.735611797216436 \t\t 50.0 \t\t 20.7154831497022\n",
      "20.83590380384172 \t\t 21.0 \t\t 27.213645804492064\n"
     ]
    }
   ],
   "source": [
    "a = predict(X_test, ww, xm, xs)\n",
    "for i in range(len(a)):\n",
    "    print(a[i], '\\t\\t', y_test[i], '\\t\\t', b[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3c32fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, x_m, x_std = linear_regression(X_train, y_train, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "3a0be335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.573096071784823 \t\t 17.1 \t\t 17.29558059208722\n",
      "12.822192853185467 \t\t 15.6 \t\t 12.14881480303195\n",
      "17.05840810124809 \t\t 21.4 \t\t 22.481784461712497\n",
      "19.433542529620286 \t\t 22.7 \t\t 22.202188867535586\n",
      "33.40470279263016 \t\t 48.3 \t\t 37.16328631468496\n",
      "21.75442951996798 \t\t 21.5 \t\t 24.915254636052772\n",
      "14.763887451466271 \t\t 20.6 \t\t 19.455161955636836\n",
      "32.926195224825975 \t\t 44.0 \t\t 37.511092390231866\n",
      "20.999748366744207 \t\t 21.7 \t\t 24.429823483247873\n",
      "16.534545947134824 \t\t 17.7 \t\t 20.17208927329338\n",
      "10.510727498657173 \t\t 19.0 \t\t 14.374785228367998\n",
      "16.91199452970177 \t\t 17.1 \t\t 19.361639540292664\n",
      "29.011730182148547 \t\t 33.2 \t\t 32.25102801323425\n",
      "28.31906206216913 \t\t 27.0 \t\t 32.708276658353974\n",
      "19.559289713658806 \t\t 20.4 \t\t 22.869524474348186\n",
      "16.58132328410346 \t\t 13.3 \t\t 20.232744140187492\n",
      "14.178084927461262 \t\t 14.9 \t\t 17.18668530858755\n",
      "22.62628631096238 \t\t 23.8 \t\t 26.402739552736584\n",
      "9.19937666760862 \t\t 11.7 \t\t 14.626176241815624\n",
      "10.065534272121624 \t\t 11.5 \t\t 14.207647351941354\n",
      "17.95045721678558 \t\t 23.1 \t\t 20.527509791162387\n",
      "22.359389610629368 \t\t 22.1 \t\t 26.878898428919722\n",
      "13.666102487090066 \t\t 14.3 \t\t 17.031418608646725\n",
      "17.46996950902993 \t\t 17.8 \t\t 19.63704691330145\n",
      "16.045283496738413 \t\t 16.4 \t\t 19.0486053324832\n",
      "24.805440158567137 \t\t 30.1 \t\t 25.40253505801478\n",
      "14.69066221132141 \t\t 12.1 \t\t 18.26126587169554\n",
      "31.29858006086834 \t\t 31.0 \t\t 34.446340892853115\n",
      "21.132995616864797 \t\t 21.7 \t\t 23.774566559646427\n",
      "33.92876036464094 \t\t 44.8 \t\t 38.37102452699322\n",
      "20.015998429872127 \t\t 19.3 \t\t 21.174181054134532\n",
      "21.984780762713587 \t\t 24.6 \t\t 24.667869132256644\n",
      "33.82629950725981 \t\t 33.3 \t\t 36.12770079210807\n",
      "19.37319003217528 \t\t 21.7 \t\t 20.906521527835256\n",
      "15.073615934547645 \t\t 20.1 \t\t 15.931185451337491\n",
      "31.22389287406752 \t\t 32.4 \t\t 36.106391643322254\n",
      "17.225472187834978 \t\t 17.5 \t\t 16.545011214380345\n",
      "23.773149831907357 \t\t 22.0 \t\t 27.4126673411188\n",
      "26.105870324043234 \t\t 24.1 \t\t 29.28719501365522\n",
      "18.191592740419402 \t\t 19.0 \t\t 21.24965774422977\n",
      "15.30510155752407 \t\t 22.5 \t\t 17.854472136580792\n",
      "19.95533831277191 \t\t 21.7 \t\t 22.392510963566224\n",
      "5.060270419505895 \t\t 5.0 \t\t 6.55162319068328\n",
      "10.532809639127489 \t\t 17.8 \t\t 9.718441392743866\n",
      "17.32419146270015 \t\t 20.4 \t\t 20.75049025935624\n",
      "28.26965807795571 \t\t 36.1 \t\t 33.20905455941134\n",
      "15.327676474853044 \t\t 50.0 \t\t 23.80072902209164\n",
      "20.257776253794297 \t\t 18.9 \t\t 21.586795681399288\n",
      "9.330252306721494 \t\t 8.3 \t\t 12.979487807352566\n",
      "9.312143539256208 \t\t 11.8 \t\t 8.72822362342302\n",
      "0.2597770052519328 \t\t 8.8 \t\t 3.2791811609612154\n",
      "21.394373489602124 \t\t 20.5 \t\t 23.972222848689483\n",
      "26.325228218340502 \t\t 33.4 \t\t 28.607036488728234\n",
      "29.024414365203633 \t\t 32.9 \t\t 30.643939064853825\n",
      "22.359941790340926 \t\t 26.5 \t\t 25.59413474573382\n",
      "23.178413982817567 \t\t 26.6 \t\t 22.148375624477346\n",
      "19.3351502745715 \t\t 24.7 \t\t 22.915026116165265\n",
      "18.775490198432262 \t\t 23.1 \t\t 22.976572190213197\n",
      "21.497477484442637 \t\t 23.1 \t\t 24.86937281538803\n",
      "16.296773896477077 \t\t 19.5 \t\t 19.774073196902535\n",
      "19.438651417164316 \t\t 23.3 \t\t 21.77537987148875\n",
      "12.937993469640881 \t\t 13.1 \t\t 13.621258906723867\n",
      "17.700677281938706 \t\t 20.0 \t\t 20.423200323014765\n",
      "29.123502167601167 \t\t 32.0 \t\t 33.42476722031544\n",
      "22.893108664098065 \t\t 21.9 \t\t 23.972283164977114\n",
      "14.785996866636925 \t\t 17.6 \t\t 16.32857560053605\n",
      "21.825958629917285 \t\t 24.7 \t\t 24.60979272545209\n",
      "15.531170150586146 \t\t 18.7 \t\t 17.872580396884885\n",
      "34.39618281665446 \t\t 45.4 \t\t 38.79756965988672\n",
      "14.955969413364347 \t\t 20.0 \t\t 18.512476092921656\n",
      "20.143846519803304 \t\t 50.0 \t\t 25.999809100736055\n",
      "31.223975663949933 \t\t 46.7 \t\t 35.456652419827925\n",
      "15.20890509964044 \t\t 19.5 \t\t 18.53994008160405\n",
      "30.803893772347053 \t\t 33.1 \t\t 34.83993381942424\n",
      "15.941050617045036 \t\t 20.6 \t\t 21.32536104399864\n",
      "25.569783679337913 \t\t 22.0 \t\t 27.356592297988144\n",
      "15.789234852127462 \t\t 22.6 \t\t 19.205480573953086\n",
      "3.1074691743792853 \t\t 10.5 \t\t 6.1284219643046285\n",
      "24.30909570345713 \t\t 23.3 \t\t 25.567527693653073\n",
      "19.9945252477882 \t\t 17.8 \t\t 22.489447908157086\n",
      "23.80337625786141 \t\t 23.1 \t\t 25.27380081685665\n",
      "22.144671140721474 \t\t 25.3 \t\t 25.203866280479183\n",
      "15.04072471739446 \t\t 10.9 \t\t 18.476828330781984\n",
      "18.007068931202312 \t\t 18.4 \t\t 19.547372850961686\n",
      "25.215251948079263 \t\t 22.0 \t\t 28.942758712750972\n",
      "28.087564661835195 \t\t 29.0 \t\t 31.713835225278082\n",
      "20.557215067392875 \t\t 19.1 \t\t 24.29082811774899\n",
      "17.796766440159214 \t\t 21.7 \t\t 20.649658642696906\n",
      "14.643573960487705 \t\t 14.6 \t\t 19.204963044918024\n",
      "16.560240623239658 \t\t 18.3 \t\t 19.108541438764995\n",
      "13.93993031832579 \t\t 16.6 \t\t 15.463976546439905\n",
      "20.805521848789436 \t\t 29.8 \t\t 25.57824626548256\n",
      "20.227703334413725 \t\t 24.3 \t\t 24.48449226906589\n",
      "28.567053087336305 \t\t 24.8 \t\t 30.771594485123202\n",
      "25.335517585344036 \t\t 28.6 \t\t 28.457643368376914\n",
      "23.967924897966228 \t\t 23.9 \t\t 27.627426095035975\n",
      "24.087028070026278 \t\t 24.8 \t\t 26.91395839359891\n",
      "23.07291793097778 \t\t 23.3 \t\t 26.60334774762085\n",
      "28.475823749422453 \t\t 30.7 \t\t 31.226735925933074\n",
      "18.23992579223762 \t\t 18.7 \t\t 20.7154831497022\n",
      "23.809217013664174 \t\t 22.3 \t\t 27.213645804492064\n"
     ]
    }
   ],
   "source": [
    "a = predict(X_test, w, x_m, x_std)\n",
    "for i in range(len(a)):\n",
    "    print(a[i], '\\t\\t', y_test[i], '\\t\\t', b[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "87d082f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "b = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
