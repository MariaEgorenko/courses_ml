{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0175cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b145f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tnet(nn.Module):\n",
    "   def __init__(self, k=3):\n",
    "      super().__init__()\n",
    "      self.k=k\n",
    "      self.conv1 = nn.Conv1d(k,64,1)\n",
    "      self.conv2 = nn.Conv1d(64,128,1)\n",
    "      self.conv3 = nn.Conv1d(128,1024,1)\n",
    "      self.fc1 = nn.Linear(1024,512)\n",
    "      self.fc2 = nn.Linear(512,256)\n",
    "      self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "      self.bn1 = nn.BatchNorm1d(64)\n",
    "      self.bn2 = nn.BatchNorm1d(128)\n",
    "      self.bn3 = nn.BatchNorm1d(1024)\n",
    "      self.bn4 = nn.BatchNorm1d(512)\n",
    "      self.bn5 = nn.BatchNorm1d(256)\n",
    "       \n",
    "\n",
    "   def forward(self, input):\n",
    "      # input.shape == (bs,n,3)\n",
    "      bs = input.size(0)\n",
    "      xb = F.relu(self.bn1(self.conv1(input)))\n",
    "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "      flat = nn.Flatten(1)(pool)\n",
    "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "      \n",
    "      #initialize as identity\n",
    "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "      if xb.is_cuda:\n",
    "        init=init.cuda()\n",
    "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "      return matrix\n",
    "\n",
    "class Transform(nn.Module):\n",
    "   def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.conv1 = nn.Conv1d(3,64,1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "       \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "       \n",
    "   def forward(self, input):\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        # batch matrix multiplication\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "        matrix64x64 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = self.bn3(self.conv3(xb))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        output = nn.Flatten(1)(xb)\n",
    "        return output, matrix3x3, matrix64x64\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, classes = 10):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, classes)\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
    "        output = self.fc3(xb)\n",
    "        return self.logsoftmax(output), matrix3x3, matrix64x64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6307a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = {\n",
    "    0: 'bathtub',\n",
    "    1: 'bed',\n",
    "    2: 'chair',\n",
    "    3: 'desk',\n",
    "    4: 'dresser',\n",
    "    5: 'monitor',\n",
    "    6: 'night_stand',\n",
    "    7: 'sofa',\n",
    "    8: 'table',\n",
    "    9: 'toilet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df072e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_off(file_path, num_points=1024):\n",
    "    mesh = o3d.io.read_triangle_mesh(file_path)\n",
    "    if mesh.is_empty():\n",
    "        raise ValueError(\"Файл пуст или не найден!\")\n",
    "\n",
    "    pcd = mesh.sample_points_uniformly(number_of_points=num_points)\n",
    "    \n",
    "    points = np.asarray(pcd.points)\n",
    "    points = points - np.mean(points, axis=0) \n",
    "    max_dist = np.max(np.sqrt(np.sum(points ** 2, axis=1)))\n",
    "    points = points / max_dist \n",
    "    \n",
    "    points = points.transpose(1, 0).astype(np.float32)\n",
    "    tensor = torch.from_numpy(points).unsqueeze(0) \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89432141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_path, image_path):\n",
    "    model = PointNet()\n",
    "    \n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "        model.eval()\n",
    "    except Exception as e:\n",
    "        print(f\"Предупреждение: Веса не загружены! ({e})\")\n",
    "        model.eval()\n",
    "\n",
    "    input_tensor = preprocess_off(image_path)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        log_probs, _, _ = model(input_tensor)\n",
    "        \n",
    "        probs = torch.exp(log_probs)\n",
    "        \n",
    "        pred_idx = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0][pred_idx].item()\n",
    "        \n",
    "    return CLASSES[pred_idx], confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585d2d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результат: TOILET\n",
      "Уверенность: 92.62%\n"
     ]
    }
   ],
   "source": [
    "file = 'src/toilet_0436.off'\n",
    "\n",
    "class_name, conf = predict('models/model.pth', file)\n",
    "\n",
    "print(f\"\\nРезультат: {class_name.upper()}\")\n",
    "print(f\"Уверенность: {conf:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffb90dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_off(filename):\n",
    "    print(f\"Загрузка файла: {filename}\")\n",
    "    \n",
    "    mesh = o3d.io.read_triangle_mesh(filename)\n",
    "    \n",
    "    if mesh.is_empty():\n",
    "        print(\"Ошибка: Файл пуст или формат не поддерживается!\")\n",
    "        return\n",
    "\n",
    "    print(f\"Успешно загружено: {len(mesh.vertices)} вершин, {len(mesh.triangles)} треугольников.\")\n",
    "\n",
    "    mesh.compute_vertex_normals()\n",
    "\n",
    "    mesh.paint_uniform_color([0.7, 0.7, 0.7]) \n",
    "\n",
    "    o3d.visualization.draw_geometries([mesh], \n",
    "                                      window_name=\"Open3D OFF Viewer\",\n",
    "                                      mesh_show_back_face=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_off(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
