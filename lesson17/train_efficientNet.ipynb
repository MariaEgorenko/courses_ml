{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2fed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8257e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc389d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dataset/food11'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06261ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE_B0 = 224\n",
    "\n",
    "data_transforms_b0 = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(IMG_SIZE_B0),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256), \n",
    "        transforms.CenterCrop(IMG_SIZE_B0), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms_b0[x])\n",
    "    for x in ['train', 'test']\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    for x in ['train', 'test']\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835916bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b0 = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "\n",
    "for param in model_b0.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model_b0.classifier[1].in_features\n",
    "\n",
    "model_b0.classifier[1] = nn.Linear(num_features, NUM_CLASSES)\n",
    "\n",
    "model_b0 = model_b0.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model_b0.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c90403dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, crit, optimizer, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                description = f'Train epoch {epoch+1}/{num_epochs}'\n",
    "            else:\n",
    "                model.eval()\n",
    "                description = f'Test epoch {epoch+1}/{num_epochs}'\n",
    "            \n",
    "            total_loss = 0.0\n",
    "            corrects = 0.0\n",
    "\n",
    "            train_tqdm = tqdm(\n",
    "                dataloaders[phase],\n",
    "                desc=description,\n",
    "                leave=True\n",
    "            )\n",
    "            for batch_idx, (images, labels) in enumerate(train_tqdm):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    out = model(images)\n",
    "                    _, preds = torch.max(out, 1)\n",
    "                    loss = crit(out, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                total_loss += loss.item() * images.size(0)\n",
    "                corrects += torch.sum(preds == labels.data) \n",
    "\n",
    "                current_loss = total_loss / (batch_idx + 1) / dataloaders[phase].batch_size\n",
    "                current_acc = corrects.double() / (batch_idx + 1) / dataloaders[phase].batch_size\n",
    "\n",
    "                train_tqdm.set_postfix(\n",
    "                    Loss=f'{current_loss:.4f}', \n",
    "                    Acc=f'{current_acc:.4f}'\n",
    "                )\n",
    "            epoch_acc = corrects / (batch_idx + 1) / dataloaders[phase].batch_size\n",
    "\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), 'best_model_food11_b0.pth')\n",
    "    \n",
    "    print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Обучение завершено за {time_elapsed // 60:.0f}м {time_elapsed % 60:.0f}с')\n",
    "    print(f'Лучшая точность на валидации: {best_acc:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4034db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1/5: 100%|██████████| 310/310 [00:23<00:00, 13.01it/s, Acc=0.7185, Loss=0.8599]\n",
      "Test epoch 1/5: 100%|██████████| 35/35 [00:04<00:00,  7.17it/s, Acc=0.7777, Loss=0.6348]\n",
      "Train epoch 2/5: 100%|██████████| 310/310 [00:24<00:00, 12.86it/s, Acc=0.7141, Loss=0.8672]\n",
      "Test epoch 2/5: 100%|██████████| 35/35 [00:04<00:00,  7.08it/s, Acc=0.7804, Loss=0.6316]\n",
      "Train epoch 3/5: 100%|██████████| 310/310 [00:24<00:00, 12.76it/s, Acc=0.7234, Loss=0.8589]\n",
      "Test epoch 3/5: 100%|██████████| 35/35 [00:05<00:00,  6.89it/s, Acc=0.7768, Loss=0.6549]\n",
      "Train epoch 4/5: 100%|██████████| 310/310 [00:24<00:00, 12.71it/s, Acc=0.7188, Loss=0.8586]\n",
      "Test epoch 4/5: 100%|██████████| 35/35 [00:05<00:00,  6.82it/s, Acc=0.7839, Loss=0.6515]\n",
      "Train epoch 5/5: 100%|██████████| 310/310 [00:24<00:00, 12.72it/s, Acc=0.7170, Loss=0.8782]\n",
      "Test epoch 5/5: 100%|██████████| 35/35 [00:05<00:00,  6.91it/s, Acc=0.7839, Loss=0.6519]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение завершено за 2м 26с\n",
      "Лучшая точность на валидации: 0.7839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_ft_b0 = train_model(model_b0, loss, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98955a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_ft_b0.features[-3:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer_ft_b0 = optim.Adam(model_ft_b0.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd02dd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1/10: 100%|██████████| 310/310 [00:28<00:00, 10.89it/s, Acc=0.7235, Loss=0.8406]\n",
      "Test epoch 1/10: 100%|██████████| 35/35 [00:04<00:00,  7.59it/s, Acc=0.7911, Loss=0.5975]\n",
      "Train epoch 2/10: 100%|██████████| 310/310 [00:28<00:00, 11.01it/s, Acc=0.7439, Loss=0.7840]\n",
      "Test epoch 2/10: 100%|██████████| 35/35 [00:04<00:00,  7.31it/s, Acc=0.7946, Loss=0.5689]\n",
      "Train epoch 3/10: 100%|██████████| 310/310 [00:29<00:00, 10.67it/s, Acc=0.7491, Loss=0.7637]\n",
      "Test epoch 3/10: 100%|██████████| 35/35 [00:05<00:00,  6.80it/s, Acc=0.8045, Loss=0.5440]\n",
      "Train epoch 4/10: 100%|██████████| 310/310 [00:30<00:00, 10.14it/s, Acc=0.7588, Loss=0.7296]\n",
      "Test epoch 4/10: 100%|██████████| 35/35 [00:05<00:00,  6.49it/s, Acc=0.8098, Loss=0.5232]\n",
      "Train epoch 5/10: 100%|██████████| 310/310 [00:30<00:00, 10.01it/s, Acc=0.7696, Loss=0.7044]\n",
      "Test epoch 5/10: 100%|██████████| 35/35 [00:05<00:00,  6.40it/s, Acc=0.8170, Loss=0.5103]\n",
      "Train epoch 6/10: 100%|██████████| 310/310 [00:32<00:00,  9.65it/s, Acc=0.7749, Loss=0.6891]\n",
      "Test epoch 6/10: 100%|██████████| 35/35 [00:05<00:00,  6.09it/s, Acc=0.8152, Loss=0.5106]\n",
      "Train epoch 7/10: 100%|██████████| 310/310 [00:29<00:00, 10.38it/s, Acc=0.7809, Loss=0.6762]\n",
      "Test epoch 7/10: 100%|██████████| 35/35 [00:05<00:00,  6.73it/s, Acc=0.8214, Loss=0.4852]\n",
      "Train epoch 8/10: 100%|██████████| 310/310 [00:29<00:00, 10.53it/s, Acc=0.7860, Loss=0.6615]\n",
      "Test epoch 8/10: 100%|██████████| 35/35 [00:05<00:00,  6.60it/s, Acc=0.8214, Loss=0.4763]\n",
      "Train epoch 9/10: 100%|██████████| 310/310 [00:29<00:00, 10.54it/s, Acc=0.7876, Loss=0.6380]\n",
      "Test epoch 9/10: 100%|██████████| 35/35 [00:05<00:00,  6.69it/s, Acc=0.8295, Loss=0.4651]\n",
      "Train epoch 10/10: 100%|██████████| 310/310 [00:29<00:00, 10.56it/s, Acc=0.7946, Loss=0.6334]\n",
      "Test epoch 10/10: 100%|██████████| 35/35 [00:05<00:00,  6.53it/s, Acc=0.8321, Loss=0.4549]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение завершено за 5м 50с\n",
      "Лучшая точность на валидации: 0.8321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_fine_tuned_b0 = train_model(\n",
    "    model_ft_b0,\n",
    "    loss, \n",
    "    optimizer_ft_b0,\n",
    "    num_epochs=10\n",
    ")\n",
    "\n",
    "torch.save(model_fine_tuned_b0.state_dict(), 'best_model_food11_b0_FINETUNED.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf1f7633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказанный класс: pizza\n",
      "Вероятность: 0.9460\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE_B0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "image_path = 'src/pizza.jpg'\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image_tensor = image_transform(image)\n",
    "\n",
    "input_batch = image_tensor.unsqueeze(0)\n",
    "\n",
    "input_batch = input_batch.to(device)\n",
    "\n",
    "model_b0.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model_b0(input_batch)\n",
    "\n",
    "    probabilities = nn.functional.softmax(out, dim=1)\n",
    "\n",
    "    top_p, top_class_index = probabilities.topk(1, dim=1)\n",
    "\n",
    "    predicted_class_name = class_names[top_class_index.item()]\n",
    "    predicted_probability = top_p.item()\n",
    "\n",
    "print(f\"Предсказанный класс: {predicted_class_name}\")\n",
    "print(f\"Вероятность: {predicted_probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a79ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE_B1 = 240\n",
    "\n",
    "data_transforms_b1 = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(IMG_SIZE_B1),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256), \n",
    "        transforms.CenterCrop(IMG_SIZE_B1), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms_b1[x])\n",
    "    for x in ['train', 'test']\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    for x in ['train', 'test']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27b0a480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b1_rwightman-bac287d4.pth\" to C:\\Users\\masha/.cache\\torch\\hub\\checkpoints\\efficientnet_b1_rwightman-bac287d4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30.1M/30.1M [00:01<00:00, 24.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_b1 = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.IMAGENET1K_V1)\n",
    "\n",
    "for param in model_b1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model_b1.classifier[1].in_features\n",
    "\n",
    "model_b1.classifier[1] = nn.Linear(num_features, NUM_CLASSES)\n",
    "\n",
    "model_b1 = model_b1.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model_b1.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "971154b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1/5: 100%|██████████| 310/310 [00:28<00:00, 10.87it/s, Acc=0.7232, Loss=0.8637]\n",
      "Test epoch 1/5: 100%|██████████| 35/35 [00:05<00:00,  6.57it/s, Acc=0.7830, Loss=0.6692]\n",
      "Train epoch 2/5: 100%|██████████| 310/310 [00:28<00:00, 10.79it/s, Acc=0.7195, Loss=0.8652]\n",
      "Test epoch 2/5: 100%|██████████| 35/35 [00:05<00:00,  6.38it/s, Acc=0.7768, Loss=0.6551]\n",
      "Train epoch 3/5: 100%|██████████| 310/310 [00:28<00:00, 10.80it/s, Acc=0.7208, Loss=0.8602]\n",
      "Test epoch 3/5: 100%|██████████| 35/35 [00:05<00:00,  6.38it/s, Acc=0.7821, Loss=0.6685]\n",
      "Train epoch 4/5: 100%|██████████| 310/310 [00:28<00:00, 10.77it/s, Acc=0.7214, Loss=0.8601]\n",
      "Test epoch 4/5: 100%|██████████| 35/35 [00:05<00:00,  6.28it/s, Acc=0.7812, Loss=0.6633]\n",
      "Train epoch 5/5: 100%|██████████| 310/310 [00:28<00:00, 10.70it/s, Acc=0.7200, Loss=0.8595]\n",
      "Test epoch 5/5: 100%|██████████| 35/35 [00:05<00:00,  6.32it/s, Acc=0.7839, Loss=0.6609]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение завершено за 2м 51с\n",
      "Лучшая точность на валидации: 0.7839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_ft_b1 = train_model(model_b1, loss, optimizer, num_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
