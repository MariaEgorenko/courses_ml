{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import EfficientNetImageProcessor, EfficientNetForImageClassification\n",
    "\n",
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "preprocessor = EfficientNetImageProcessor.from_pretrained(\"google/efficientnet-b0\")\n",
    "model = EfficientNetForImageClassification.from_pretrained(\"google/efficientnet-b0\")\n",
    "\n",
    "inputs = preprocessor(image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_label = logits.argmax(-1).item()\n",
    "print(model.config.id2label[predicted_label]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6113345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_corrupted_images(data_dir, extensions=('.jpg', '.jpeg', '.png')):\n",
    "    corrupted = []\n",
    "    for img_path in Path(data_dir).rglob('*'):\n",
    "        if img_path.suffix.lower() in extensions:\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                img.load()  # Быстрая проверка целостности\n",
    "            except (IOError, OSError, Image.UnidentifiedImageError) as e:\n",
    "                print(f\"Битый файл: {img_path} — {e}\")\n",
    "                corrupted.append(str(img_path))\n",
    "                img = Image.new('RGB', (224, 224), color='black')\n",
    "    return corrupted\n",
    "\n",
    "path_data = 'dataset/food11'\n",
    "\n",
    "\n",
    "for t in ['test', 'train']:\n",
    "    pt = os.path.join(path_data, t)\n",
    "    for cls in pt:\n",
    "        find_corrupted_images(cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd654c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apple_pie: 100%|██████████| 100/100 [00:00<00:00, 138.50it/s]\n",
      "cheesecake: 100%|██████████| 100/100 [00:00<00:00, 116.95it/s]\n",
      "chicken_curry: 100%|██████████| 100/100 [00:00<00:00, 122.43it/s]\n",
      "french_fries: 100%|██████████| 100/100 [00:00<00:00, 120.47it/s]\n",
      "fried_rice: 100%|██████████| 100/100 [00:00<00:00, 112.58it/s]\n",
      "hamburger: 100%|██████████| 100/100 [00:00<00:00, 103.15it/s]\n",
      "hot_dog: 100%|██████████| 100/100 [00:00<00:00, 115.50it/s]\n",
      "ice_cream: 100%|██████████| 100/100 [00:00<00:00, 111.09it/s]\n",
      "omelette: 100%|██████████| 100/100 [00:00<00:00, 125.92it/s]\n",
      "pizza: 100%|██████████| 100/100 [00:00<00:00, 125.56it/s]\n",
      "sushi: 100%|██████████| 100/100 [00:00<00:00, 116.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1100\n",
      "cat 100, dog 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apple_pie: 100%|██████████| 900/900 [00:07<00:00, 113.30it/s]\n",
      "cheesecake: 100%|██████████| 900/900 [00:09<00:00, 98.24it/s] \n",
      "chicken_curry: 100%|██████████| 900/900 [00:08<00:00, 111.77it/s]\n",
      "french_fries: 100%|██████████| 900/900 [00:07<00:00, 119.11it/s]\n",
      "fried_rice: 100%|██████████| 900/900 [00:07<00:00, 115.37it/s]\n",
      "hamburger: 100%|██████████| 900/900 [00:07<00:00, 113.04it/s]\n",
      "hot_dog: 100%|██████████| 900/900 [00:07<00:00, 116.06it/s]\n",
      "ice_cream: 100%|██████████| 900/900 [00:07<00:00, 114.61it/s]\n",
      "omelette: 100%|██████████| 900/900 [00:07<00:00, 116.04it/s]\n",
      "pizza: 100%|██████████| 900/900 [00:07<00:00, 117.97it/s]\n",
      "sushi: 100%|██████████| 900/900 [00:08<00:00, 111.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9900\n",
      "cat 900, dog 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "emun_dir = [('apple_pie', 0), ('cheesecake', 1), ('chicken_curry', 2),\n",
    "            ('french_fries', 3), ('fried_rice', 4), ('hamburger', 5),\n",
    "            ('hot_dog', 6), ('ice_cream', 7), ('omelette', 8), \n",
    "            ('pizza', 9), ('sushi', 10)]\n",
    "\n",
    "def scan_and_clean_data(root_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for label_name, label_id in emun_dir:\n",
    "        path = os.path.join(root_dir, label_name)\n",
    "                \n",
    "        for filename in tqdm(os.listdir(path), desc=f\"{label_name}\"):\n",
    "            file_path = os.path.join(path, filename)\n",
    "            \n",
    "            if not filename.lower().endswith(('.jpg', '.jpeg')):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                img.load()\n",
    "                \n",
    "                if img.mode not in ('RGB', 'L'):\n",
    "                    continue\n",
    "\n",
    "                image_paths.append(file_path)\n",
    "                labels.append(label_id)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    print(f\"total {len(labels)}\")\n",
    "    print(f\"cat {labels.count(0)}, dog {labels.count(1)}\")\n",
    "    return image_paths, labels\n",
    "\n",
    "path_data = 'dataset/food11'\n",
    "\n",
    "\n",
    "for t in ['test', 'train']:\n",
    "    scan_and_clean_data(os.path.join(path_data, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3961458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.efficientnet import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7140c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils import data\n",
    "\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b5bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)), \n",
    "    transforms.ToTensor(),                       \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "855aab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((450, 450)), \n",
    "    transforms.ToTensor(),                       \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "204457ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class minclass4torch(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.placeholder_image = Image.new('RGB', (224, 224), color = 'black')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = self.placeholder_image\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2353e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ['test', 'train']:\n",
    "    all_image_paths, all_labels = scan_and_clean_data(os.path.join(path_data, t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09aa8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = minclass4torch(all_image_paths, all_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6929db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root='dataset/food11/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='dataset/food11/test', transform=transform_val)\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=32, num_workers=4)\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=32, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17054a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64dc1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c198c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eff = models.efficientnet_b7( weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e32fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_eff.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "l = model_eff.classifier[-1].in_features\n",
    "\n",
    "model_eff.classifier[-1] = nn.Linear(in_features=l, out_features=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe964fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eff.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "452b83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ac06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_eff.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a4065ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 (Train): 100%|██████████| 310/310 [03:06<00:00,  1.66it/s, Loss=1.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "  -> avg loss train: 2.8455\n",
      "  -> F1 test: 0.0512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 (Train): 100%|██████████| 310/310 [03:07<00:00,  1.65it/s, Loss=1.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "  -> avg loss train: 2.8836\n",
      "  -> F1 test: 0.0822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 (Train): 100%|██████████| 310/310 [03:02<00:00,  1.69it/s, Loss=1.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "  -> avg loss train: 2.8215\n",
      "  -> F1 test: 0.1184\n",
      "final F1 0.1184\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "all_targets = []\n",
    "all_preds = []\n",
    "\n",
    "def check_f1_score(model, loader, device):\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            \n",
    "            scores = model(x)\n",
    "            \n",
    "            _, predictions = scores.max(1)\n",
    "            \n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro') \n",
    "    model.train()\n",
    "    return f1\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model_eff.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    train_loop = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} (Train)\")\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loop):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        scores = model_eff(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "        \n",
    "        train_loop.set_postfix(Loss=loss.item())\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    val_f1 = check_f1_score(model_eff, test_dataloader, device)\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"  -> avg loss train: {avg_train_loss:.4f}\")\n",
    "    print(f\"  -> F1 test: {val_f1:.4f}\")\n",
    "    \n",
    "final_f1 = check_f1_score(model_eff, test_dataloader, device)\n",
    "print(f\"final F1 {final_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7b999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
